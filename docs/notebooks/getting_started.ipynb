{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸƒ Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sAhEeGluAWxR",
    "outputId": "08ab2c66-e1bc-4ed1-a9cf-cba3dcb94b68"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "import numpy.testing as npt\n",
    "\n",
    "import finitediffx as fdx\n",
    "\n",
    "\n",
    "# lets first define a vector valued function F: R^3 -> R^3\n",
    "# F = F1, F2\n",
    "# F1 = x^2 + y^3\n",
    "# F2 = x^4 + y^3\n",
    "# F3 = 0\n",
    "# F = [x**2 + y**3, x**4 + y**3, 0]\n",
    "\n",
    "x, y, z = [jnp.linspace(0, 1, 100)] * 3\n",
    "dx, dy, dz = x[1] - x[0], y[1] - y[0], z[1] - z[0]\n",
    "X, Y, Z = jnp.meshgrid(x, y, z, indexing=\"ij\")\n",
    "F1 = X**2 + Y**3\n",
    "F2 = X**4 + Y**3\n",
    "F3 = jnp.zeros_like(F1)\n",
    "F = jnp.stack([F1, F2, F3], axis=0)\n",
    "\n",
    "# âˆ‚F1/âˆ‚x : differentiate F1 with respect to x (i.e axis=0)\n",
    "dF1dx = fdx.difference(\n",
    "    F1,\n",
    "    axis=0,\n",
    "    step_size=dx,\n",
    "    accuracy=6,\n",
    "    method=\"central\",\n",
    ")\n",
    "dF1dx_exact = 2 * X\n",
    "npt.assert_allclose(dF1dx, dF1dx_exact, atol=1e-7)\n",
    "\n",
    "# âˆ‚F2/âˆ‚y : differentiate F2 with respect to y (i.e axis=1)\n",
    "dF2dy = fdx.difference(\n",
    "    F2,\n",
    "    axis=1,\n",
    "    step_size=dy,\n",
    "    accuracy=6,\n",
    "    method=\"central\",\n",
    ")\n",
    "dF2dy_exact = 3 * Y**2\n",
    "npt.assert_allclose(dF2dy, dF2dy_exact, atol=1e-7)\n",
    "\n",
    "# âˆ‡.F : the divergence of F\n",
    "divF = fdx.divergence(\n",
    "    F,\n",
    "    step_size=(dx, dy, dz),\n",
    "    keepdims=False,\n",
    "    accuracy=6,\n",
    "    method=\"central\",\n",
    ")\n",
    "divF_exact = 2 * X + 3 * Y**2\n",
    "npt.assert_allclose(divF, divF_exact, atol=1e-7)\n",
    "\n",
    "# âˆ‡F1 : the gradient of F1\n",
    "gradF1 = fdx.gradient(\n",
    "    F1,\n",
    "    step_size=(dx, dy, dz),\n",
    "    accuracy=6,\n",
    "    method=\"central\",\n",
    ")\n",
    "gradF1_exact = jnp.stack([2 * X, 3 * Y**2, 0 * X], axis=0)\n",
    "npt.assert_allclose(gradF1, gradF1_exact, atol=1e-7)\n",
    "\n",
    "# Î”F1 : laplacian of F1\n",
    "lapF1 = fdx.laplacian(\n",
    "    F1,\n",
    "    step_size=(dx, dy, dz),\n",
    "    accuracy=6,\n",
    "    method=\"central\",\n",
    ")\n",
    "lapF1_exact = 2 + 6 * Y\n",
    "npt.assert_allclose(lapF1, lapF1_exact, atol=1e-7)\n",
    "\n",
    "# âˆ‡xF : the curl of F\n",
    "curlF = fdx.curl(\n",
    "    F,\n",
    "    step_size=(dx, dy, dz),\n",
    "    accuracy=6,\n",
    "    method=\"central\",\n",
    ")\n",
    "curlF_exact = jnp.stack([F1 * 0, F1 * 0, 4 * X**3 - 3 * Y**2], axis=0)\n",
    "npt.assert_allclose(curlF, curlF_exact, atol=1e-7)\n",
    "\n",
    "# Jacobian of F\n",
    "JF = fdx.jacobian(\n",
    "    F,\n",
    "    accuracy=4,\n",
    "    step_size=(dx, dy, dz),\n",
    "    method=\"central\",\n",
    ")\n",
    "JF_exact = jnp.array(\n",
    "    [\n",
    "        [2 * X, 3 * Y**2, jnp.zeros_like(X)],\n",
    "        [4 * X**3, 3 * Y**2, jnp.zeros_like(X)],\n",
    "        [jnp.zeros_like(X), jnp.zeros_like(X), jnp.zeros_like(X)],\n",
    "    ]\n",
    ")\n",
    "npt.assert_allclose(JF, JF_exact, atol=1e-7)\n",
    "\n",
    "# Hessian of F1\n",
    "HF1 = fdx.hessian(\n",
    "    F1,\n",
    "    accuracy=4,\n",
    "    step_size=(dx, dy, dz),\n",
    "    method=\"central\",\n",
    ")\n",
    "HF1_exact = jnp.array(\n",
    "    [\n",
    "        [\n",
    "            2 * jnp.ones_like(X),  # âˆ‚2F1/âˆ‚x2\n",
    "            0 * jnp.ones_like(X),  # âˆ‚2F1/âˆ‚xy\n",
    "            0 * jnp.ones_like(X),  # âˆ‚2F1/âˆ‚xz\n",
    "        ],\n",
    "        [\n",
    "            0 * jnp.ones_like(X),  # âˆ‚2F1/âˆ‚yx\n",
    "            6 * Y**2,  # âˆ‚2F1/âˆ‚y2\n",
    "            0 * jnp.ones_like(X),  # âˆ‚2F1/âˆ‚yz\n",
    "        ],\n",
    "        [\n",
    "            0 * jnp.ones_like(X),  # âˆ‚2F1/âˆ‚zx\n",
    "            0 * jnp.ones_like(X),  # âˆ‚2F1/âˆ‚zy\n",
    "            0 * jnp.ones_like(X),  # âˆ‚2F1/âˆ‚z2\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "npt.assert_allclose(JF, JF_exact, atol=1e-7)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPb3/ZgzpaTTXlbaGk5dBZL",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
