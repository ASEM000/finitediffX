{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASEM000/FiniteDiffX/blob/main/FiniteDiffX%20Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VseGGGblAX5R"
      },
      "outputs": [],
      "source": [
        "!pip install finitediffx --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAhEeGluAWxR",
        "outputId": "08ab2c66-e1bc-4ed1-a9cf-cba3dcb94b68"
      },
      "outputs": [],
      "source": [
        "\n",
        "import jax\n",
        "\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "import jax.numpy as jnp\n",
        "import numpy.testing as npt\n",
        "\n",
        "import finitediffx as fdx\n",
        "\n",
        "\n",
        "# lets first define a vector valued function F: R^3 -> R^3\n",
        "# F = F1, F2\n",
        "# F1 = x^2 + y^3\n",
        "# F2 = x^4 + y^3\n",
        "# F3 = 0\n",
        "# F = [x**2 + y**3, x**4 + y**3, 0]\n",
        "\n",
        "x, y, z = [jnp.linspace(0, 1, 100)] * 3\n",
        "dx, dy, dz = x[1] - x[0], y[1] - y[0], z[1] - z[0]\n",
        "X, Y, Z = jnp.meshgrid(x, y, z, indexing=\"ij\")\n",
        "F1 = X**2 + Y**3\n",
        "F2 = X**4 + Y**3\n",
        "F3 = jnp.zeros_like(F1)\n",
        "F = jnp.stack([F1, F2, F3], axis=0)\n",
        "\n",
        "# ∂F1/∂x : differentiate F1 with respect to x (i.e axis=0)\n",
        "dF1dx = fdx.difference(F1, axis=0, step_size=dx, accuracy=6, method=\"central\")\n",
        "dF1dx_exact = 2 * X\n",
        "npt.assert_allclose(dF1dx, dF1dx_exact, atol=1e-7)\n",
        "\n",
        "# ∂F2/∂y : differentiate F2 with respect to y (i.e axis=1)\n",
        "dF2dy = fdx.difference(F2, axis=1, step_size=dy, accuracy=6, method=\"central\")\n",
        "dF2dy_exact = 3 * Y**2\n",
        "npt.assert_allclose(dF2dy, dF2dy_exact, atol=1e-7)\n",
        "\n",
        "# ∇.F : the divergence of F\n",
        "divF = fdx.divergence(F, step_size=(dx, dy, dz), keepdims=False, accuracy=6, method=\"central\")\n",
        "divF_exact = 2 * X + 3 * Y**2\n",
        "npt.assert_allclose(divF, divF_exact, atol=1e-7)\n",
        "\n",
        "# ∇F1 : the gradient of F1\n",
        "gradF1 = fdx.gradient(F1, step_size=(dx, dy, dz), accuracy=6, method=\"central\")\n",
        "gradF1_exact = jnp.stack([2 * X, 3 * Y**2, 0 * X], axis=0)\n",
        "npt.assert_allclose(gradF1, gradF1_exact, atol=1e-7)\n",
        "\n",
        "# ΔF1 : laplacian of F1\n",
        "lapF1 = fdx.laplacian(F1, step_size=(dx, dy, dz), accuracy=6, method=\"central\")\n",
        "lapF1_exact = 2 + 6 * Y\n",
        "npt.assert_allclose(lapF1, lapF1_exact, atol=1e-7)\n",
        "\n",
        "# ∇xF : the curl of F\n",
        "curlF = fdx.curl(F, step_size=(dx, dy, dz), accuracy=6, method=\"central\")\n",
        "curlF_exact = jnp.stack([F1 * 0, F1 * 0, 4 * X**3 - 3 * Y**2], axis=0)\n",
        "npt.assert_allclose(curlF, curlF_exact, atol=1e-7)\n",
        "\n",
        "# Jacobian of F\n",
        "JF = fdx.jacobian(F, accuracy=4, step_size=(dx, dy, dz), method=\"central\")\n",
        "JF_exact = jnp.array(\n",
        "    [\n",
        "        [2 * X, 3 * Y**2, jnp.zeros_like(X)],\n",
        "        [4 * X**3, 3 * Y**2, jnp.zeros_like(X)],\n",
        "        [jnp.zeros_like(X), jnp.zeros_like(X), jnp.zeros_like(X)],\n",
        "    ]\n",
        ")\n",
        "npt.assert_allclose(JF, JF_exact, atol=1e-7)\n",
        "\n",
        "# Hessian of F1\n",
        "HF1 = fdx.hessian(F1, accuracy=4, step_size=(dx, dy, dz), method=\"central\")\n",
        "HF1_exact = jnp.array(\n",
        "    [\n",
        "        [\n",
        "            2 * jnp.ones_like(X),  # ∂2F1/∂x2\n",
        "            0 * jnp.ones_like(X),  # ∂2F1/∂xy\n",
        "            0 * jnp.ones_like(X),  # ∂2F1/∂xz\n",
        "        ],\n",
        "        [\n",
        "            0 * jnp.ones_like(X),  # ∂2F1/∂yx\n",
        "            6 * Y**2,              # ∂2F1/∂y2\n",
        "            0 * jnp.ones_like(X),  # ∂2F1/∂yz\n",
        "        ],\n",
        "        [\n",
        "            0 * jnp.ones_like(X),  # ∂2F1/∂zx\n",
        "            0 * jnp.ones_like(X),  # ∂2F1/∂zy\n",
        "            0 * jnp.ones_like(X),  # ∂2F1/∂z2\n",
        "        ],\n",
        "    ]\n",
        ")\n",
        "npt.assert_allclose(JF, JF_exact, atol=1e-7)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPb3/ZgzpaTTXlbaGk5dBZL",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
